{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "sys.path.insert(0,\"/dartfs-hpc/rc/home/w/f003k8w/.local/lib/python3.7/site-packages/\")\n",
    "\n",
    "from pathflowai.utils import load_sql_df\n",
    "import torch\n",
    "import pickle\n",
    "import os \n",
    "# import umap, numba\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch_cluster import knn_graph\n",
    "from torch_geometric.data import Data \n",
    "import numpy as np\n",
    "from torch_geometric.utils import train_test_split_edges\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=\"0\"\n",
    "import argparse\n",
    "from torch_geometric.utils.convert import to_networkx\n",
    "from torch_geometric.data import InMemoryDataset,DataLoader\n",
    "import os,glob, pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "import copy\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from collections import Counter\n",
    "from torch import nn\n",
    "from torch_geometric.nn import GCNConv, GATConv, DeepGraphInfomax, SAGEConv\n",
    "from torch_geometric.nn import DenseGraphConv\n",
    "from torch_geometric.utils import to_dense_batch, to_dense_adj, dense_to_sparse\n",
    "from torch_geometric.nn import GINEConv\n",
    "from torch_geometric.utils import dropout_adj\n",
    "from torch_geometric.nn import APPNP\n",
    "import torch.nn as nn\n",
    "import fire\n",
    "\n",
    "EPS = 1e-15\n",
    "\n",
    "class GCNNet(torch.nn.Module):\n",
    "    def __init__(self, inp_dim, out_dim, hidden_topology=[32,64,128,128], p=0.5, p2=0.1, drop_each=True):\n",
    "        super(GCNNet, self).__init__()\n",
    "        self.out_dim=out_dim\n",
    "        self.convs = nn.ModuleList([GATConv(inp_dim, hidden_topology[0])]+[GATConv(hidden_topology[i],hidden_topology[i+1]) for i in range(len(hidden_topology[:-1]))])\n",
    "        self.drop_edge = lambda edge_index: dropout_adj(edge_index,p=p2)[0]\n",
    "        self.dropout = nn.Dropout(p)\n",
    "        self.fc = nn.Linear(hidden_topology[-1], out_dim)\n",
    "        self.drop_each=drop_each\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr=None):\n",
    "        for conv in self.convs:\n",
    "            if self.drop_each and self.training: edge_index=self.drop_edge(edge_index)\n",
    "            x = F.relu(conv(x, edge_index, edge_attr))\n",
    "        if self.training:\n",
    "            x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "class GCNFeatures(torch.nn.Module):\n",
    "    def __init__(self, gcn, bayes=False, p=0.05, p2=0.1):\n",
    "        super(GCNFeatures, self).__init__()\n",
    "        self.gcn=gcn\n",
    "        self.drop_each=bayes\n",
    "        self.gcn.drop_edge = lambda edge_index: dropout_adj(edge_index,p=p2)[0]\n",
    "        self.gcn.dropout = nn.Dropout(p)\n",
    "    \n",
    "    def forward(self, x, edge_index, edge_attr=None):\n",
    "        for i,conv in enumerate(self.gcn.convs):\n",
    "            if self.drop_each: edge_index=self.gcn.drop_edge(edge_index)\n",
    "            x = conv(x, edge_index, edge_attr)\n",
    "            if i+1<len(self.gcn.convs):\n",
    "                x=F.relu(x)\n",
    "        if self.drop_each:\n",
    "            x = self.gcn.dropout(x)\n",
    "        y = self.gcn.fc(F.relu(x))#F.softmax()\n",
    "        return x,y\n",
    "\n",
    "def extract_features(cv_split=2,\n",
    "                graph_data='datasets/graph_dataset_no_pretrain.pkl',\n",
    "                cv_splits='cv_splits/cv_splits.pkl',\n",
    "                models_dir=\"models_no_pretrain/\",\n",
    "                out_dir='predictions_no_pretrain',\n",
    "                hidden_topology=[32,64,128,128],\n",
    "                p=0.5,\n",
    "                p2=0.3,\n",
    "                n_posterior=50\n",
    "                ):\n",
    "    # prep data\n",
    "    datasets=pickle.load(open(graph_data,'rb'))\n",
    "    cv_splits=pickle.load(open(cv_splits,'rb'))[cv_split]\n",
    "    train_dataset=[datasets['graph_dataset'][i] for i in cv_splits['train_idx']]\n",
    "    val_dataset=[datasets['graph_dataset'][i] for i in np.hstack((cv_splits['train_idx'],cv_splits['val_idx']))]#,cv_splits['test_idx']consider adding val_idx to help optimize\n",
    "\n",
    "    # load model\n",
    "    model=GCNNet(datasets['graph_dataset'][0].x.shape[1],datasets['df']['annotation'].nunique(),hidden_topology=hidden_topology,p=p,p2=p2)\n",
    "    model=model.cuda()\n",
    "    \n",
    "    # load previous save\n",
    "    model.load_state_dict(torch.load(os.path.join(models_dir,f\"{cv_split}.model.pth\")))\n",
    "\n",
    "    # dataloaders\n",
    "    dataloaders={}\n",
    "\n",
    "    dataloaders['train']=DataLoader(train_dataset,shuffle=True)\n",
    "    dataloaders['val']=DataLoader(val_dataset,shuffle=False)\n",
    "    dataloaders['warmup']=DataLoader(train_dataset,shuffle=False)\n",
    "    train_loader=dataloaders['warmup']\n",
    "\n",
    "    # uncertainty test\n",
    "    model.eval()\n",
    "    feature_extractor=GCNFeatures(model,bayes=True,p=p,p2=p2).cuda()\n",
    "    graphs=[]\n",
    "    \n",
    "    for i,data in enumerate(dataloaders['val']):\n",
    "        with torch.no_grad():\n",
    "            graph = to_networkx(data).to_undirected()\n",
    "            model.train(False)\n",
    "            x=data.x.cuda()\n",
    "            xy=data.pos.numpy()\n",
    "            edge_index=data.edge_index.cuda()\n",
    "            y=data.y.numpy()\n",
    "            preds=torch.stack([feature_extractor(x,edge_index)[1] for j in range(n_posterior)]).cpu().numpy()\n",
    "            graphs.append(dict(y=y,G=graph,xy=xy,y_pred_posterior=preds.mean(0),y_std=preds.std(0)))\n",
    "            del x,edge_index\n",
    "    model.eval()\n",
    "    feature_extractor=GCNFeatures(model,bayes=False).cuda()\n",
    "    for i,data in enumerate(dataloaders['val']):\n",
    "        with torch.no_grad():\n",
    "            graph = to_networkx(data).to_undirected()\n",
    "            model.train(False)\n",
    "            x=data.x.cuda()\n",
    "            xy=data.pos.numpy()\n",
    "            edge_index=data.edge_index.cuda()\n",
    "            y=data.y.numpy()\n",
    "            preds=feature_extractor(x,edge_index)\n",
    "            z,y_pred=preds[0].detach().cpu().numpy(),preds[1].detach().cpu().numpy()\n",
    "            graphs[i].update(dict(z=z,y_pred=y_pred))\n",
    "            del x,edge_index\n",
    "    torch.save(graphs,os.path.join(out_dir,f\"{cv_split}.predictions.pth\"))\n",
    "    \n",
    "class Commands(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def extract_features(self,cv_split=2,\n",
    "                graph_data='datasets/graph_dataset_no_pretrain.pkl',\n",
    "                cv_splits='cv_splits/cv_splits.pkl',\n",
    "                models_dir=\"models_no_pretrain/\",\n",
    "                out_dir='predictions_no_pretrain',\n",
    "                hidden_topology=[32,64,128,128],\n",
    "                p=0.5,\n",
    "                p2=0.3,\n",
    "                n_posterior=50\n",
    "                ):\n",
    "        extract_features(cv_split,\n",
    "                        graph_data,\n",
    "                        cv_splits,\n",
    "                        models_dir,\n",
    "                        out_dir,\n",
    "                        hidden_topology,\n",
    "                        p,\n",
    "                        p2,\n",
    "                        n_posterior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "your_args=dict(cv_split=4,\n",
    "                graph_data='bcc/graph_datasets/pretrain_graph_data_256.pkl',\n",
    "                cv_splits='bcc/graph_datasets/cv_splits_256_pretrain.pkl',\n",
    "                models_dir=\"bcc/gnn_models/\",\n",
    "                out_dir='bcc/predictions',\n",
    "                hidden_topology=[32]*3,\n",
    "                p=0.3,\n",
    "                p2=0.2,\n",
    "                n_posterior=100)\n",
    "Commands().extract_features(**your_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\r\n",
      "Mem:            376          61         276           1          38         311\r\n",
      "Swap:             3           2           1\r\n"
     ]
    }
   ],
   "source": [
    "! free -g "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
