{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! ln 1_WebApp_Practice.ipynb ../ArcticAI_Prototype/workflow/\n",
    "! cd ../ArcticAI_Prototype/ && git add * */* && git commit -a -m \"workflow update\" && git push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results class for display\n",
    "import pandas as pd, numpy as np\n",
    "from scipy.ndimage import label as scilabel\n",
    "from skimage.measure import regionprops_table\n",
    "import cv2, os, subprocess\n",
    "from deepzoom import *\n",
    "from deepzoom import _get_or_create_path,_get_files_path\n",
    "from PIL import Image\n",
    "import tqdm\n",
    "import dask\n",
    "from dask.diagnostics import ProgressBar\n",
    "from scipy.special import softmax\n",
    "import torch\n",
    "from sauth import SimpleHTTPAuthHandler, serve_http\n",
    "from skimage.draw import circle\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "\n",
    "colors=dict(red=np.array([255,0,0]),\n",
    "           blue=np.array([0,0,255]),\n",
    "           green=np.array([0,255,0]),\n",
    "           yellow=np.array([255,255,0]))\n",
    "\n",
    "class Numpy2DZI(ImageCreator):\n",
    "    def __init__(\n",
    "        self,\n",
    "        tile_size=254,\n",
    "        tile_overlap=1,\n",
    "        tile_format=\"jpg\",\n",
    "        image_quality=0.8,\n",
    "        resize_filter=None,\n",
    "        copy_metadata=False,\n",
    "        compression=1.\n",
    "    ):\n",
    "        super().__init__(tile_size,tile_overlap,tile_format,image_quality,resize_filter,copy_metadata)\n",
    "        self.compression=compression\n",
    "        \n",
    "    def create(self, source_arr, destination):\n",
    "        # potentially have an option where dynamically softlink once deeper layer is made so slide is readily available, push to background process and write metadata for dash app to read  \n",
    "        # speed up image saving with dask https://stackoverflow.com/questions/54615625/how-to-save-dask-array-as-png-files-slice-by-slice https://github.com/dask/dask-image/issues/110\n",
    "        self.image = PIL.Image.fromarray(source_arr if self.compression==1 else cv2.resize(source_arr,None,fx=1/self.compression,fy=1/self.compression,interpolation=cv2.INTER_CUBIC))\n",
    "        width, height = self.image.size\n",
    "        self.descriptor = DeepZoomImageDescriptor(\n",
    "            width=width,\n",
    "            height=height,\n",
    "            tile_size=self.tile_size,\n",
    "            tile_overlap=self.tile_overlap,\n",
    "            tile_format=self.tile_format,\n",
    "        )\n",
    "        image_files = _get_or_create_path(_get_files_path(destination))\n",
    "        for level in tqdm.trange(self.descriptor.num_levels, desc='level'):\n",
    "            level_dir = _get_or_create_path(os.path.join(image_files, str(level)))\n",
    "            level_image = self.get_image(level)\n",
    "            for (column, row) in tqdm.tqdm(self.tiles(level), desc='tiles'):\n",
    "                bounds = self.descriptor.get_tile_bounds(level, column, row)\n",
    "                tile = level_image.crop(bounds)\n",
    "                format = self.descriptor.tile_format\n",
    "                tile_path = os.path.join(level_dir, \"%s_%s.%s\" % (column, row, format))\n",
    "                tile_file = open(tile_path, \"wb\")\n",
    "                if self.descriptor.tile_format == \"jpg\":\n",
    "                    jpeg_quality = int(self.image_quality * 100)\n",
    "                    tile.save(tile_file, \"JPEG\", quality=jpeg_quality)\n",
    "                else:\n",
    "                    tile.save(tile_file)\n",
    "        self.descriptor.save(destination)\n",
    "        return destination\n",
    "        \n",
    "@dask.delayed\n",
    "def write_dzi(img, out_dzi, compression=8):\n",
    "    return Numpy2DZI(compression=compression).create(img,out_dzi)\n",
    "\n",
    "def add_depth(x):\n",
    "    x=x.sort_values(['slide_id',\"section_id\"])\n",
    "    x['depth']=np.arange(1,len(x)+1)\n",
    "    return x\n",
    "\n",
    "def mask2label(mask,compression=8):\n",
    "    mask_small=cv2.resize(mask.astype(int),None,fx=1/compression,fy=1/compression,interpolation=cv2.INTER_NEAREST).astype(bool)\n",
    "    label=cv2.resize(scilabel(mask_small)[0],dsize=mask.shape[::-1],interpolation=cv2.INTER_NEAREST)\n",
    "    return label\n",
    "\n",
    "class Case:\n",
    "    def __init__(self, patient=\"163_A1\"):\n",
    "        self.launch_dir=os.path.abspath(\".\")\n",
    "        self.patient=patient\n",
    "        self.results=pd.read_pickle(f\"results/{patient}.pkl\")\n",
    "        self.slide_metadata,self.section_metadata=self.add_metadata(self.results)\n",
    "        self.n_slides=self.results['n_slides']\n",
    "        self.slide_cache=self.slide_metadata.copy()\n",
    "        self.section_cache=self.section_metadata.copy()\n",
    "        self.slide_cache['label']=''\n",
    "        self.slide_cache['tumor_map']=''\n",
    "        self.slide_cache['macro_map']=''\n",
    "        self.slide_cache['region_props']=''\n",
    "        self.slide_inks={}\n",
    "        self.section_metadata['quality']=''\n",
    "        self.max_depth=self.section_metadata['depth'].max()\n",
    "        self.n_blocks=self.section_metadata['block_id'].max()\n",
    "        self.extraction_methods=dict(image=self.extract_section_image,\n",
    "                                    tumor=self.extract_tumor_results,\n",
    "                                    ink=self.extract_ink_results,\n",
    "                                    nuclei=self.extract_nuclei_results)\n",
    "        for k in self.extraction_methods.keys(): self.section_cache[f\"{k}_dzi\"]=''\n",
    "        \n",
    "        \n",
    "    def add_metadata(self, results):\n",
    "        slide_metadata=pd.DataFrame({k:results[k] for k in results if isinstance(results[k],list)}).reset_index().rename(columns=dict(index=\"slide_id\"))\n",
    "        slide_metadata['slide_id']+=1\n",
    "        section_metadata=dict(slide_id=[],\n",
    "                             block_id=[],\n",
    "                             section_id=[],\n",
    "                             label_id=[])\n",
    "        for slide in slide_metadata['slide_id'].values:\n",
    "            section_metadata['label_id'].extend(np.arange(1,results['n_sections_per_slide']*results['n_blocks_per_section']+1))\n",
    "            section_metadata['slide_id'].extend([slide]*(results['n_sections_per_slide']*results['n_blocks_per_section']))\n",
    "            section_metadata['block_id'].extend(np.arange(1,results['n_blocks_per_section']+1).tolist()*results['n_sections_per_slide'])\n",
    "            for i in range(1,results['n_sections_per_slide']+1): section_metadata['section_id'].extend([i]*results['n_blocks_per_section'])\n",
    "        section_metadata=pd.DataFrame(section_metadata)\n",
    "        section_metadata['id']=np.arange(len(section_metadata))\n",
    "        section_metadata=pd.DataFrame(section_metadata.groupby(\"block_id\").apply(add_depth)).reset_index(drop=True).sort_values(['id'])\n",
    "        return slide_metadata,section_metadata\n",
    "            \n",
    "    \n",
    "    def compute_quality(self, importance_regions={'dermis':3.,'epidermis':1.,'subcutaneous tissue':2.},\n",
    "                                importance_tumor=4.,\n",
    "                                distance_weight=0.7,\n",
    "                                baseline_region=1.):\n",
    "        \n",
    "        quality_scores=self.slide_metadata['quality_scores'].map(pd.read_pickle)\n",
    "\n",
    "        self.tumor_quality_scores=pd.concat([quality_scores[i]['tumor'] for i in range(self.n_slides)],axis=1).fillna(0).T.reset_index(drop=True)\n",
    "        self.macro_quality_scores=pd.concat([quality_scores[i]['macro'] for i in range(self.n_slides)],axis=1).fillna(0).T.reset_index(drop=True)\n",
    "\n",
    "        self.section_metadata['quality']=np.nan\n",
    "        for block_id in self.section_metadata['block_id'].unique():\n",
    "            idx=self.section_metadata['block_id'].values==block_id\n",
    "            section_metadata_ids=self.section_metadata['id'].loc[idx]\n",
    "            macro_qual,tumor_qual=self.macro_quality_scores.loc[idx],self.tumor_quality_scores.loc[idx]\n",
    "            for i in range(len(macro_qual)):\n",
    "                macro_qual['distance_weight']=distance_weight**(np.abs(macro_qual.index-i))\n",
    "                tumor_qual['distance_weight']=distance_weight**(np.abs(tumor_qual.index-i))\n",
    "                quality_score=pd.concat([importance_regions[region]*(macro_qual[region]*(baseline_region+tumor_qual[region]*tumor_qual[\"distance_weight\"])) for region in importance_regions]+[importance_tumor*tumor_qual['hole']*tumor_qual[\"distance_weight\"]],axis=1)\n",
    "                quality_score.columns=list(importance_regions)+['hole']\n",
    "                self.section_metadata.loc[self.section_metadata['id']==section_metadata_ids[i],'quality']=quality_score.values.sum()\n",
    "\n",
    "    def load_slide(self, slide, compression=8):\n",
    "        slide_loc=self.get_slide_loc(slide)\n",
    "        if self.slide_cache.loc[slide_loc,['images','masks','label']].map(lambda x: isinstance(x,str)).sum()>0:\n",
    "            self.slide_cache.loc[slide_loc,['images','masks']]=self.slide_metadata.loc[slide_loc,['images','masks']].map(np.load)\n",
    "            self.slide_cache.loc[slide_loc,'label']=[mask2label(self.slide_cache.loc[slide_loc,'masks'],compression)]\n",
    "            self.slide_cache.loc[slide_loc,'region_props']=[regionprops_table(self.slide_cache.loc[slide_loc,'label'], properties=['bbox'])] \n",
    "        image,mask,label=self.slide_cache.loc[slide_loc,['images','masks','label']].tolist()\n",
    "        return image,mask,label\n",
    "    \n",
    "    def get_slide_loc(self, slide):\n",
    "        return self.slide_metadata.index[np.where(self.slide_metadata['slide_id']==slide)[0][0]]\n",
    "    \n",
    "    def get_section_bbox(self, slide_id, label_id):\n",
    "        slide_loc=self.get_slide_loc(slide_id)\n",
    "        bbox=pd.DataFrame(self.slide_cache.loc[slide_loc,'region_props'])\n",
    "        bbox.columns=['xmin','ymin','xmax','ymax']\n",
    "        bbox.index+=1\n",
    "        xmin,ymin,xmax,ymax=bbox.loc[label_id]\n",
    "        return xmin,ymin,xmax,ymax\n",
    "    \n",
    "    def load_nuclei(self, slide):\n",
    "        slide_loc=self.get_slide_loc(slide)\n",
    "        if not isinstance(self.slide_cache.loc[slide_loc,'nuclei_results'],np.ndarray):\n",
    "            nuclei_result=np.load(self.slide_cache.loc[slide_loc,'nuclei_results'])\n",
    "            self.slide_cache.loc[slide_loc,'nuclei_results']=[nuclei_result]\n",
    "        else: nuclei_result=self.slide_cache.loc[slide_loc,'nuclei_results']\n",
    "        return nuclei_result \n",
    "    \n",
    "    def load_tumor_map(self, slide, alpha=0.1, patch_size=256, low_res=True):\n",
    "        assert low_res, \"High resolution label propagation completed, but not available as an option yet\"\n",
    "        slide_loc=self.get_slide_loc(slide)\n",
    "        if not isinstance(self.slide_cache.loc[slide_loc,'tumor_gnn_results'],np.ndarray):\n",
    "            graphs=torch.load(self.slide_cache.loc[slide_loc,'tumor_gnn_results'])\n",
    "            xy=np.vstack([graph['xy'] for graph in graphs]).astype(int)\n",
    "            y_pred=softmax(np.vstack([graph['y_pred'] for graph in graphs]),1)[:,1].reshape(-1,1)\n",
    "            img_=self.load_slide(slide)[0].copy()\n",
    "            one_square=np.ones((patch_size,patch_size)).astype(np.float)*255\n",
    "            for x,y,pred in tqdm.tqdm(np.hstack([xy,y_pred]).tolist(), desc='tumor'):\n",
    "                x,y=map(int,[x,y])\n",
    "                img_[x:x+patch_size,y:y+patch_size]=alpha*cv2.applyColorMap(np.uint8(pred*one_square), cv2.COLORMAP_JET)+(1-alpha)*img_[x:x+patch_size,y:y+patch_size]\n",
    "            self.slide_cache.loc[slide_loc,'tumor_gnn_results']=[img_]\n",
    "        else: img_=self.slide_cache.loc[slide_loc,'tumor_gnn_results']\n",
    "        return img_\n",
    "    \n",
    "    def load_ink(self, slide):\n",
    "        slide_loc=self.get_slide_loc(slide)\n",
    "        ink_file=self.slide_cache.loc[slide_loc,'ink_results']\n",
    "        self.slide_inks.update({slide_loc:self.slide_inks.get(slide_loc,pd.read_pickle(ink_file))})\n",
    "        return self.slide_inks[slide_loc]\n",
    "\n",
    "    def extract_section_image(self, depth, block_id, compression=8):\n",
    "        section=self.section_metadata.loc[(self.section_metadata['depth']==depth) & (self.section_metadata['block_id']==block_id)]\n",
    "        label_id,slide_id=section.loc[:,['label_id','slide_id']].values.flatten()\n",
    "        image,mask,label=self.load_slide(slide_id,compression)\n",
    "        xmin,ymin,xmax,ymax=self.get_section_bbox(slide_id,label_id)\n",
    "        \n",
    "        img=image[xmin:xmax,ymin:ymax].copy()\n",
    "        img[label[xmin:xmax,ymin:ymax]!=label_id]=255\n",
    "        return img\n",
    "    \n",
    "    def extract_tumor_results(self, depth, block_id, alpha=0.3, patch_size=256, low_res=True, compression=8):\n",
    "        section=self.section_metadata.loc[(self.section_metadata['depth']==depth) & (self.section_metadata['block_id']==block_id)]\n",
    "        label_id,slide_id=section.loc[:,['label_id','slide_id']].values.flatten()\n",
    "        _,mask,label=self.load_slide(slide_id,compression)\n",
    "        xmin,ymin,xmax,ymax=self.get_section_bbox(slide_id,label_id)\n",
    "        tumor_map=self.load_tumor_map(slide_id, alpha=alpha, patch_size=patch_size, low_res=low_res)\n",
    "                \n",
    "        img=tumor_map[xmin:xmax,ymin:ymax].copy()\n",
    "        img[label[xmin:xmax,ymin:ymax]!=label_id]=255\n",
    "        return img\n",
    "    \n",
    "    def extract_nuclei_results(self, depth, block_id, compression=8):\n",
    "        section=self.section_metadata.loc[(self.section_metadata['depth']==depth) & (self.section_metadata['block_id']==block_id)]\n",
    "        label_id,slide_id=section.loc[:,['label_id','slide_id']].values.flatten()\n",
    "        image,mask,label=self.load_slide(slide_id,compression)\n",
    "        xmin,ymin,xmax,ymax=self.get_section_bbox(slide_id,label_id)\n",
    "        \n",
    "        nuclei=self.load_nuclei(slide_id)\n",
    "        \n",
    "        img=image[xmin:xmax,ymin:ymax].copy()\n",
    "        nuc_mask=nuclei[xmin:xmax,ymin:ymax].copy()\n",
    "        img[nuc_mask,:]=[255,0,0]\n",
    "        img[label[xmin:xmax,ymin:ymax]!=label_id]=255\n",
    "        return img\n",
    "    \n",
    "    def extract_ink_results(self, depth, block_id, circle_size=200, compression=8):\n",
    "        section=self.section_metadata.loc[(self.section_metadata['depth']==depth) & (self.section_metadata['block_id']==block_id)]\n",
    "        label_id,slide_id=section.loc[:,['label_id','slide_id']].values.flatten()\n",
    "        image,mask,label=self.load_slide(slide_id,compression)\n",
    "        xmin,ymin,xmax,ymax=self.get_section_bbox(slide_id,label_id)\n",
    "        xy_min=np.array([xmin,ymin])\n",
    "        ink=self.load_ink(slide_id)[label_id]\n",
    "        ink=ink.map(lambda x: (x-xy_min).astype(int))\n",
    "        img=image[xmin:xmax,ymin:ymax].copy()\n",
    "        max_size=np.array(img.shape[:2])\n",
    "        for k in colors:\n",
    "            if k!=\"center_mass\": \n",
    "                ink_k=ink.loc[k]\n",
    "                remove=(~np.any((ink_k-max_size)>0,axis=1))\n",
    "                ink_k=ink_k[remove]\n",
    "                img[ink_k[:,0],ink_k[:,1],:]=colors[k]\n",
    "            else: \n",
    "                xx,yy=circle(*(ink.loc[k].astype(int).tolist()), circle_size)\n",
    "                img[xx,yy,:]=[0,0,0]\n",
    "        img[label[xmin:xmax,ymin:ymax]!=label_id]=255\n",
    "        return img    \n",
    "    \n",
    "    def write_dzi(self, img, out_dzi, compression=8):\n",
    "        Numpy2DZI(compression=compression).create(img,out_dzi)\n",
    "        \n",
    "    def write_dzi_parallel(self, img_dzi_dict, compression=8, scheduler='processes'):\n",
    "        written_dzis=[]\n",
    "        for out_dzi, img in img_dzi_dict.items():\n",
    "            written_dzis.append(write_dzi(img, out_dzi, compression))\n",
    "        with ProgressBar():\n",
    "            written_dzis=dask.compute(*written_dzis, scheduler=scheduler)\n",
    "        return written_dzis\n",
    "    \n",
    "    def launch_server(self, username='username', password='password', port=5554):\n",
    "        self.reset_dir()\n",
    "        SimpleHTTPAuthHandler.username = username\n",
    "        SimpleHTTPAuthHandler.password = password\n",
    "        serve_http(ip='localhost', port=port, https=False,\n",
    "               start_dir='dzi_files', handler_class=SimpleHTTPAuthHandler)\n",
    "        \n",
    "    def reset_dir(self):\n",
    "        os.chdir(self.launch_dir)\n",
    "    \n",
    "    def visualize_dzi(self, dzis):\n",
    "        self.reset_dir()\n",
    "        replace_txt='\",\"'.join(list(map(os.path.basename,dzis)))\n",
    "        with open(\"osd_template.html\") as f_in, open('dzi_files/index.html','w') as f_out:\n",
    "            f_out.write(f_in.read().replace(\"REPLACE\",replace_txt).replace(\"BASENAME\",self.patient))\n",
    "            \n",
    "    def extract2dzi(self, image_type='image', scheduler='single-threaded'):\n",
    "        assert image_type in ['image','nuclei','tumor','ink']\n",
    "        dzi_files=[]\n",
    "        imgs={}\n",
    "        for block in tqdm.trange(1,self.n_blocks+1, desc='block'):\n",
    "            for depth in tqdm.trange(1,self.max_depth+1, desc='depth'):\n",
    "                section_info=[self.patient,depth,block,image_type]\n",
    "                dzi_file=f\"dzi_files/{'_'.join(list(map(str,section_info)))}.dzi\"\n",
    "                dzi_files.append(dzi_file)\n",
    "                if not os.path.exists(dzi_file):\n",
    "                    imgs[dzi_file]=self.extraction_methods[image_type](depth,block)\n",
    "        if len(imgs)>0: self.write_dzi_parallel(imgs,scheduler=scheduler)\n",
    "        self.section_cache[f\"{image_type}_dzi\"]=self.section_cache[['depth','block_id']].apply(lambda x: f\"dzi_files/{'_'.join([self.patient]+x.values.astype(str).tolist()+[image_type])}.dzi\",axis=1)\n",
    "        return dzi_files\n",
    "        \n",
    "            \n",
    "    # add dzi check and database to reference and view dzi of particular layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix, then adopt https://dash-gallery.plotly.host/dash-financial-report/\n",
    "# sauth --dir dzi_files/ user pass localhost 5555\n",
    "# https://github.com/thedirtyfew/terracotta-dash-example/blob/master/app.py\n",
    "# https://github.com/plotly/dash-sample-apps/blob/master/apps/dash-financial-report/app.py\n",
    "# one terminal launches server, other terminal runs this app, third terminal forwards app; 3 ports\n",
    "from jupyter_dash import JupyterDash\n",
    "import plotly.express as px\n",
    "import dash_bootstrap_components as dbc\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "import dash_table, os, time, glob, numpy as np\n",
    "from dash.dependencies import Output, Input\n",
    "from dash.exceptions import PreventUpdate\n",
    "\n",
    "app = JupyterDash(__name__,external_stylesheets=[dbc.themes.COSMO],assets_folder=os.path.abspath(\"dzi_files\"))\n",
    "server = app.server\n",
    "\n",
    "layouts=dict()\n",
    "elements=dict()\n",
    "all_app_data=dict(case=None,\n",
    "                 url=\"http://127.0.0.1:5558\",\n",
    "                 image_types=['image','tumor','nuclei','ink'])\n",
    "\n",
    "\n",
    "\n",
    "cases=[dict(label=x,value=x) for x in np.vectorize(lambda f: os.path.basename(f).replace(\".pkl\",\"\"))(glob.glob(\"results/*.pkl\"))]\n",
    "\n",
    "elements['case_block_depth_labels']=[dbc.Col(html.Label(x)) for x in ['Case:',\"Block:\",\"Depth:\"]]\n",
    "\n",
    "elements['case_block_depth']=[dbc.Col(x) for x in [\n",
    "                                dcc.Dropdown(options=cases,value=None,id=\"case_id\", multi=False),\n",
    "                                dcc.Dropdown(options=[],value=None,id=\"block_id\", multi=False),\n",
    "                                dcc.Slider(min=1,max=1000, step=1,value=1,id=\"depth_id\")\n",
    "                                ]\n",
    "                             ]\n",
    "\n",
    "layouts['tab1']=dbc.Container([\n",
    "                    dbc.Row([\n",
    "                            dbc.Col([\n",
    "                              html.Div(html.Iframe(id='openseadragon',\n",
    "                                        src=all_app_data['url'],width='800',height='800'),id='wsi')  \n",
    "                                ]),\n",
    "                            dbc.Col([\n",
    "                              dbc.Row(elements['case_block_depth_labels']),\n",
    "                              dbc.Row(elements['case_block_depth'])\n",
    "                                ])                           \n",
    "                            ])\n",
    "                    ], \n",
    "                    fluid=True)\n",
    "\n",
    "elements['quality_score_labels']=[dbc.Col(html.Label(x)) for x in ['Tumor Quality:',\"Hole Quality:\", \"Overall Quality:\"]]\n",
    "\n",
    "elements['quality_score']=[dbc.Col(x) for x in [\n",
    "                            dcc.Graph(style=dict(width='800',height='800'),id='tumor_quality'),\n",
    "                            dcc.Graph(style=dict(width='800',height='800'),id='hole_quality'),\n",
    "                            dcc.Graph(style=dict(width='800',height='800'),id='overall_quality')\n",
    "                            ]\n",
    "                          ]\n",
    "                                  \n",
    "elements['block_depth_labels']=[dbc.Col(html.Label(x)) for x in [\"Block:\",\"Depth:\"]]\n",
    "\n",
    "elements['block_depth']=[dbc.Col(x) for x in [\n",
    "                                dcc.Dropdown(options=[],value=None,id=\"block_id2\", multi=False),\n",
    "                                dcc.Slider(min=1,max=1000, step=1,value=1,id=\"depth_id2\")\n",
    "                                ]\n",
    "                             ]\n",
    "\n",
    "layouts['tab2']=dbc.Container([\n",
    "                    dbc.Row([\n",
    "                        dbc.Col([\n",
    "#                               dbc.Row(elements['quality_score_labels']),\n",
    "                              dbc.Row(elements['quality_score'])\n",
    "                                ]),\n",
    "                        dbc.Col([\n",
    "                              dbc.Row(elements['block_depth_labels']),\n",
    "                              dbc.Row(elements['block_depth'])\n",
    "                                ])\n",
    "                    ])\n",
    "                ])\n",
    "\n",
    "tabs = html.Div(\n",
    "    [\n",
    "        dbc.Tabs(\n",
    "            [\n",
    "                dbc.Tab(label=\"Visualize Results\", tab_id=\"tab-1\", children=layouts['tab1']),\n",
    "                dbc.Tab(label=\"Quality Assessment\", tab_id=\"tab-2\", children=layouts['tab2']),\n",
    "\n",
    "            ],\n",
    "            id=\"tabs\",\n",
    "            active_tab=\"tab-1\",\n",
    "        ),\n",
    "        html.Div(id=\"content\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "app.layout = tabs\n",
    "\n",
    "def prevent_update_check(conditional):\n",
    "    global all_app_data\n",
    "    if (conditional) or all_app_data['case'] is None: raise PreventUpdate\n",
    "\n",
    "@app.callback(\n",
    "    [Output(\"block_id\", \"options\"),\n",
    "    Output(\"block_id2\", \"options\"),\n",
    "    Output('tumor_quality','figure'),\n",
    "    Output('hole_quality','figure'),\n",
    "    Output('overall_quality','figure')],\n",
    "    [Input('case_id','value')]\n",
    ")\n",
    "def update_case(case):\n",
    "    global all_app_data\n",
    "    if case is None: raise PreventUpdate\n",
    "    all_app_data[\"case\"]=Case(patient=case)\n",
    "    all_app_data[\"case\"].compute_quality()\n",
    "    dzis=dict(image=[],nuclei=[],tumor=[],ink=[])\n",
    "    for k in dzis:\n",
    "        dzis[k]=all_app_data[\"case\"].extract2dzi(k)\n",
    "    all_app_data[\"dzis\"]=dzis\n",
    "    blocks=all_app_data[\"case\"].section_cache['block_id'].unique()\n",
    "    return ([[dict(label=f\"Block: {block}\",value=block) for block in blocks]]*2)+[px.imshow(all_app_data[\"case\"].tumor_quality_scores,title='Tumor Quality:'),px.imshow(all_app_data[\"case\"].macro_quality_scores,title=\"Hole Quality:\"),px.imshow(all_app_data[\"case\"].section_metadata['quality'].values.reshape(-1,1),title=\"Overall Quality:\")]\n",
    "\n",
    "@app.callback(\n",
    "    [Output(\"depth_id\", \"min\"),\n",
    "    Output(\"depth_id\", \"max\"),\n",
    "    Output(\"depth_id\", \"marks\")],\n",
    "    [Input('block_id','value')]\n",
    ")\n",
    "def update_depth(block):\n",
    "    global all_app_data\n",
    "    prevent_update_check(block is None)\n",
    "    depths=all_app_data[\"case\"].section_cache.loc[all_app_data[\"case\"].section_cache['block_id']==block,'depth'].unique()\n",
    "    return [depths.min(),depths.max(),{int(depth):str(depth) for depth in sorted(depths)}]\n",
    "                                  \n",
    "@app.callback(\n",
    "    [Output(\"depth_id2\", \"min\"),\n",
    "    Output(\"depth_id2\", \"max\"),\n",
    "    Output(\"depth_id2\", \"marks\")],\n",
    "    [Input('block_id2','value')]\n",
    ")\n",
    "def update_depth2(block):\n",
    "    global all_app_data\n",
    "    prevent_update_check(block is None)\n",
    "    depths=all_app_data[\"case\"].section_cache.loc[all_app_data[\"case\"].section_cache['block_id']==block,'depth'].unique()\n",
    "    return [depths.min(),depths.max(),{int(depth):str(depth) for depth in sorted(depths)}]\n",
    "\n",
    "@app.callback(\n",
    "    Output(\"wsi\", \"children\"),\n",
    "    [Input('block_id','value'),\n",
    "    Input('depth_id','value')]\n",
    ")\n",
    "def update_wsi_plot(block, depth):\n",
    "    global all_app_data\n",
    "    prevent_update_check(block is None)\n",
    "    dzis=all_app_data[\"case\"].section_cache.loc[(all_app_data[\"case\"].section_cache['block_id']==block) & (all_app_data[\"case\"].section_cache['depth']==depth),[f\"{k}_dzi\" for k in all_app_data['image_types']]].values.flatten().tolist()\n",
    "    prevent_update_check(len(dzis)==0)\n",
    "    all_app_data[\"case\"].visualize_dzi(dzis)\n",
    "    return html.Iframe(id=f'openseadragon_{np.random.random_sample()}',\n",
    "                src=all_app_data['url'],width='800',height='800')\n",
    "           \n",
    "# add block and depth specific macro/tumor quality; quality scores\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "port=5556\n",
    "# app._terminate_server_for_port(\"localhost\", port)\n",
    "app.run_server(debug=True,mode=\"external\",host='localhost',port=port)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slide_id</th>\n",
       "      <th>block_id</th>\n",
       "      <th>section_id</th>\n",
       "      <th>label_id</th>\n",
       "      <th>id</th>\n",
       "      <th>depth</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>32.640948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>32.921537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>33.190469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>32.679864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>31.761142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>31.007711</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   slide_id  block_id  section_id  label_id  id  depth    quality\n",
       "0         1         1           1         1   0      1  32.640948\n",
       "1         1         1           2         2   1      2  32.921537\n",
       "2         2         1           1         1   2      3  33.190469\n",
       "3         2         1           2         2   3      4  32.679864\n",
       "4         3         1           1         1   4      5  31.761142\n",
       "5         3         1           2         2   5      6  31.007711"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_app_data[\"case\"].section_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
