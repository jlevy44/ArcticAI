{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, torch, numpy as np, pandas as pd\n",
    "import pickle\n",
    "import scipy.sparse as sps\n",
    "from torch_geometric.utils import subgraph, add_remaining_self_loops\n",
    "from torch_cluster import radius_graph\n",
    "from collections import Counter\n",
    "from torch_geometric.data import Data \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def return_true_label(patch_info,analysis_type):\n",
    "    le=LabelEncoder()\n",
    "    tissue_types=['dermis','subcutaneous tissue','epidermis','hole']\n",
    "    classes_=np.array(patch_info.columns[6:].tolist()+['unassigned'])\n",
    "    classes_y=le.fit_transform(classes_)\n",
    "    classes_dict=dict(zip(le.classes_,classes_y))\n",
    "    classes_dict['unassigned']=-1\n",
    "    if analysis_type=='macro':\n",
    "        for k in tissue_types:\n",
    "            patch_info.loc[patch_info[k]>0.,'annotation']=k\n",
    "    patch_info.loc[:,'y_true']=patch_info.loc[:,'annotation'].map(classes_dict)\n",
    "    return patch_info\n",
    "\n",
    "# modify, add unassigned\n",
    "def create_graph_data(basename=\"163_A1a\",\n",
    "                      analysis_type=\"tumor\",\n",
    "                      radius=256,\n",
    "                      min_component_size=600):\n",
    "    embeddings=torch.load(os.path.join(\"cnn_embeddings\",analysis_type,f\"{basename}.pkl\"))\n",
    "    embeddings['patch_info']=return_true_label(embeddings['patch_info'],analysis_type)\n",
    "    xy=torch.tensor(embeddings['patch_info'][['x','y']].values).float().cuda()\n",
    "    X=torch.tensor(embeddings['embeddings'])\n",
    "    y_true=torch.tensor(embeddings['patch_info']['y_true'].values.flatten()).long()\n",
    "    G=radius_graph(xy, r=radius*np.sqrt(2), batch=None, loop=True)\n",
    "    G=G.detach().cpu()\n",
    "    G=add_remaining_self_loops(G)[0]\n",
    "    xy=xy.detach().cpu()\n",
    "    datasets=[]\n",
    "    edges=G.detach().cpu().numpy().astype(int)\n",
    "    n_components,components=list(sps.csgraph.connected_components(sps.coo_matrix((np.ones_like(edges[0]),(edges[0],edges[1])))))\n",
    "    comp_count=Counter(components)\n",
    "    components=torch.LongTensor(components)\n",
    "    for i in range(n_components):\n",
    "        if comp_count[i]>=min_component_size:\n",
    "            G_new=subgraph(components==i,G,relabel_nodes=True)[0]\n",
    "            xy_new=xy[components==i]\n",
    "            X_new=X[components==i]\n",
    "            np.random.seed(42)\n",
    "            idx=np.arange(X_new.shape[0])\n",
    "            idx2=np.arange(X_new.shape[0])\n",
    "            np.random.shuffle(idx)\n",
    "            train_idx,val_idx,test_idx=torch.tensor(np.isin(idx2,idx[:int(0.8*len(idx))])),torch.tensor(np.isin(idx2,idx[int(0.8*len(idx)):int(0.9*len(idx))])),torch.tensor(np.isin(idx2,idx[int(0.9*len(idx)):]))\n",
    "            dataset=Data(x=X_new, edge_index=G_new, y_true=y_true[components==i], edge_attr=None, pos=xy_new)\n",
    "            dataset.mask=y_true[components==i]==-1\n",
    "            dataset.train_mask=train_idx\n",
    "            dataset.val_mask=val_idx\n",
    "            dataset.test_mask=test_idx\n",
    "            dataset.id=basename\n",
    "            dataset.component=i\n",
    "            datasets.append(dataset)\n",
    "    pickle.dump(datasets,open(os.path.join('graph_datasets',analysis_type,f\"{basename}.pkl\"),'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_graph_data(basename=\"108_A1c\",\n",
    "                      analysis_type=\"macro\",\n",
    "                      radius=256,\n",
    "                      min_component_size=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 114/114 [12:09<00:00,  6.40s/it]\n"
     ]
    }
   ],
   "source": [
    "import tqdm,glob\n",
    "for f in tqdm.tqdm(glob.glob(\"cnn_embeddings/*/*.pkl\")):\n",
    "    analysis_type,basename=f.replace(\".pkl\",\"\").split(\"/\")[-2:]\n",
    "    create_graph_data(basename=basename,\n",
    "                      analysis_type=analysis_type,\n",
    "                      radius=256,\n",
    "                      min_component_size=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108_A1c.pkl  15_A1a.pkl  37_A2eX.pkl  44_A1c.pkl  5_A1eX.pkl  85_A1b.pkl\r\n",
      "108_A1d.pkl  20_B1d.pkl  3_A2b.pkl    46_A2b.pkl  60_A1c.pkl  90_A2b.pkl\r\n",
      "125_A2b.pkl  36_B2e.pkl  3_A2c.pkl    47_A1c.pkl  60_A1d.pkl  91_A2b.pkl\r\n",
      "125_A2d.pkl  37_A1c.pkl  41_A2b.pkl   53_A1b.pkl  66_A1b.pkl  9_A7b.pkl\r\n",
      "153_A1d.pkl  37_A2d.pkl  43_A2b.pkl   5_A1d.pkl   78_A2d.pkl\r\n"
     ]
    }
   ],
   "source": [
    "# GENERATE THUMBNAILS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile, os, pandas as pd, cv2, numpy as np, pickle\n",
    "def generate_thumbnail(graph_dataset_file,compression=16):\n",
    "    analysis_type,basename=graph_dataset_file.replace(\".pkl\",\"\").split(\"/\")[-2:]\n",
    "    img_dirname=\"new_skin_layers/Skin_Layer_ASAP_TIFF\" if analysis_type=='macro' else \"new_test_slides/ASAP_Tiff\"\n",
    "    img=tifffile.imread(os.path.join(img_dirname,f\"{basename}_ASAP.tif\"))\n",
    "    graph_dataset=pd.read_pickle(graph_dataset_file)\n",
    "    thumbnails=[]\n",
    "    for i,graph in enumerate(graph_dataset):\n",
    "        xmin,ymin,xmax,ymax=np.hstack([graph.pos.min(0).values.numpy(),graph.pos.max(0).values.numpy()]).astype(int)\n",
    "        arr=img[xmin:xmax,ymin:ymax,:]\n",
    "        thumbnails.append(cv2.resize(arr,None,fx=1/compression,fy=1/compression,interpolation=cv2.INTER_CUBIC))\n",
    "    pickle.dump(thumbnails,open(os.path.join(\"thumbnails\",analysis_type,f\"{basename}.pkl\"),'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 114/114 [20:25<00:00, 10.75s/it]\n"
     ]
    }
   ],
   "source": [
    "import tqdm, glob\n",
    "for f in tqdm.tqdm(glob.glob(\"graph_datasets/*/*.pkl\")):\n",
    "    generate_thumbnail(f,compression=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
